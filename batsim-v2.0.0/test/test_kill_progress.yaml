base_output_directory: /tmp/batsim_tests/kill_progress
base_variables:
  batsim_dir: ${base_working_directory}
implicit_instances:
  implicit:
    sweep:
      platform :
        - {"name":"small", "filename":"${batsim_dir}/platforms/small_platform.xml", "master_host":"master_host"}
      workload :
        - {"name":"tiny_compute", "filename": "${batsim_dir}/workload_profiles/one_computation_job.json"}
        - {"name":"tiny_delay", "filename": "${batsim_dir}/workload_profiles/one_delay_job.json"}
        - {"name":"test_all", "filename": "${batsim_dir}/workload_profiles/test_workload_profile.json"}
      algo:
        - {"name":"killer", "sched_name":"killer"}
      delay_before_kill: [0,5]
      nb_kills_per_job: [1]
    generic_instance:
      timeout: 10
      working_directory: ${base_working_directory}
      output_directory: ${base_output_directory}/results/${instance_id}
      batsim_command: ${BATSIM_BIN:=batsim} -p ${platform[filename]} -w ${workload[filename]} -e ${output_directory}/out -m ${platform[master_host]} -vnetwork-only
      sched_command: ${BATSCHED_BIN:=batsched} -v ${algo[sched_name]} --variant_options_filepath ${output_directory}/sched_input.json
      commands_before_execution:
        # Generate sched input
        - |
              #!/usr/bin/env bash
              cat > ${output_directory}/sched_input.json << EOF
              {
                "nb_kills_per_job": ${nb_kills_per_job},
                "delay_before_kill": ${delay_before_kill}
              }
              EOF
      commands_after_execution:
        - |
          cat ${output_directory}/batsim.stderr | \grep -o "Sending '.*'" | \cut -d "'" -f2 | \grep 'JOB_KILLED' > ${output_directory}/messages.txt

        # Let's check if job progress is present in all killed job
        - |
            #!/usr/bin/env bash
            source ${output_directory}/variables.bash

            cat > ${output_directory}/jobs_analysis.py <<EOF
            #!/usr/bin/env python3
            import json
            import pandas as pd
            import re
            import sys

            # workload = json.load(open('${workload[filename]}'))

            msg_file = open('${output_directory}/messages.txt')
            msg_str = msg_file.read()

            msgs = msg_str.strip().split('\n')

            errors = []
            for msg in msgs:
                json_msg = json.loads(msg)
                for event in json_msg['events']:
                    if event['type'] == 'JOB_KILLED':
                        job_data = event['data']
                        if 'job_progress' not in job_data:
                            errors.append(job_data + " do not contains job progress\n")
                        #TODO test if this job is msg or delay of composed
                        #and test the progress content type in regards

            if errors:
                print(error)
                sys.exit(1)
            else:
                sys.exit(0)

            EOF
        - chmod +x ${output_directory}/jobs_analysis.py
        - ${output_directory}/jobs_analysis.py



commands_before_instances:
  - ${batsim_dir}/test/is_batsim_dir.py ${base_working_directory}
  - ${batsim_dir}/test/clean_output_dir.py ${base_output_directory}
